{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a8ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.nn import DenseSAGEConv, dense_diff_pool, dense_mincut_pool\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "from dataset import load_pyg_dataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958fd080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84862405",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling = 'mincut' #(options: diffpool, mincut)\n",
    "dataset_name = 'Twitch-RU'\n",
    "\n",
    "#Pooling selector\n",
    "pooling_selector = {\n",
    "    'diffpool': dense_diff_pool,\n",
    "    'mincut': dense_mincut_pool\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a817d4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The obtained data Twitch-RU has 4385 nodes, 78993 edges, 128 features, 2 labels, \n"
     ]
    }
   ],
   "source": [
    "data = load_pyg_dataset(\n",
    "    data_name=dataset_name,\n",
    "    device=device\n",
    ")\n",
    "num_clusters = data.y.max().tolist()+1\n",
    "data.adj = to_dense_adj(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0f2508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d578c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GNN to compute transformed node features for pooling (for assignation matrix)\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels,\n",
    "                 normalize=False, lin=True):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = DenseSAGEConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseSAGEConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseSAGEConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "        if lin is True:\n",
    "            self.lin = torch.nn.Linear(\n",
    "                2 * hidden_channels + out_channels,\n",
    "                out_channels\n",
    "            )\n",
    "        else:\n",
    "            self.lin = None\n",
    "            \n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, 'bn{}'.format(i))(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x0 = x\n",
    "        if pooling == 'diffpool':\n",
    "            x1 = self.bn(1, F.relu(self.conv1(x0, adj, mask)))\n",
    "            x2 = self.bn(2, F.relu(self.conv2(x1, adj, mask)))\n",
    "            x3 = self.bn(3, F.relu(self.conv3(x2, adj, mask)))\n",
    "        elif pooling == 'mincut':\n",
    "            x1 = F.relu(self.conv1(x0, adj, mask))\n",
    "            x2 = F.relu(self.conv2(x1, adj, mask))\n",
    "            x3 = F.relu(self.conv3(x2, adj, mask))\n",
    "        x = torch.cat([x1, x2, x3], dim=-1)\n",
    "        if self.lin is not None:\n",
    "            x = F.relu(self.lin(x))\n",
    "        return x\n",
    "\n",
    "#Net to compute pooling in an unsupervised manner\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.gnn1_pool = GNN(data.num_node_features, 64, num_clusters)\n",
    "        self.gnn1_embed = GNN(data.num_node_features, 64, 64, lin=False)\n",
    "        self.pooling = pooling_selector[pooling]\n",
    "        \n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x, adj, l1, e1 = self.pooling(x, adj, s, mask)\n",
    "        return torch.softmax(s, dim=-1), l1, e1 # returns assignation matrix, and auxiliary losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991bd0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd5206aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "#Training\n",
    "###########\n",
    "#Optimizer, model\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#Trains using auxiliary losses only\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    s, l1, e1 = model(data.x, data.adj)\n",
    "    loss = l1 + e1\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "#Measures mutual information of clustering computed by pooling and ground truth\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    pred_node_label = model(data.x, data.adj)[0].max(dim=-1)[1].detach().cpu().numpy() \n",
    "    truth_node_labels = data.y.cpu().numpy()\n",
    "    nmi = normalized_mutual_info_score(truth_node_labels.flatten(), pred_node_label.flatten())\n",
    "    return nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c836c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98dd0e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: -0.23608363, Val NMI: 0.0001, Test NMI: 0.0001\n",
      "Epoch: 002, Train Loss: -0.23774678, Val NMI: 0.0002, Test NMI: 0.0002\n",
      "Epoch: 003, Train Loss: -0.23969305, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 004, Train Loss: -0.24214876, Val NMI: 0.0002, Test NMI: 0.0002\n",
      "Epoch: 005, Train Loss: -0.24522078, Val NMI: 0.0003, Test NMI: 0.0003\n",
      "Epoch: 006, Train Loss: -0.24906558, Val NMI: 0.0003, Test NMI: 0.0003\n",
      "Epoch: 007, Train Loss: -0.25378245, Val NMI: 0.0004, Test NMI: 0.0004\n",
      "Epoch: 008, Train Loss: -0.25953442, Val NMI: 0.0004, Test NMI: 0.0004\n",
      "Epoch: 009, Train Loss: -0.26649177, Val NMI: 0.0002, Test NMI: 0.0002\n",
      "Epoch: 010, Train Loss: -0.27478069, Val NMI: 0.0001, Test NMI: 0.0001\n",
      "Epoch: 011, Train Loss: -0.28451955, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 012, Train Loss: -0.29575616, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 013, Train Loss: -0.30857784, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 014, Train Loss: -0.32299548, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 015, Train Loss: -0.33904159, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 016, Train Loss: -0.35662323, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 017, Train Loss: -0.37561166, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 018, Train Loss: -0.39575580, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 019, Train Loss: -0.41670299, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 020, Train Loss: -0.43809530, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 021, Train Loss: -0.45962507, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 022, Train Loss: -0.48087427, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 023, Train Loss: -0.50144756, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 024, Train Loss: -0.52098739, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 025, Train Loss: -0.53927577, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 026, Train Loss: -0.55619550, Val NMI: 0.0001, Test NMI: 0.0001\n",
      "Epoch: 027, Train Loss: -0.57169306, Val NMI: 0.0001, Test NMI: 0.0001\n",
      "Epoch: 028, Train Loss: -0.58584827, Val NMI: 0.0002, Test NMI: 0.0002\n",
      "Epoch: 029, Train Loss: -0.59871042, Val NMI: 0.0002, Test NMI: 0.0002\n",
      "Epoch: 030, Train Loss: -0.61035627, Val NMI: 0.0002, Test NMI: 0.0002\n",
      "Epoch: 031, Train Loss: -0.62090147, Val NMI: 0.0001, Test NMI: 0.0001\n",
      "Epoch: 032, Train Loss: -0.63043261, Val NMI: 0.0001, Test NMI: 0.0001\n",
      "Epoch: 033, Train Loss: -0.63907355, Val NMI: 0.0001, Test NMI: 0.0001\n",
      "Epoch: 034, Train Loss: -0.64688766, Val NMI: 0.0001, Test NMI: 0.0001\n",
      "Epoch: 035, Train Loss: -0.65394491, Val NMI: 0.0001, Test NMI: 0.0001\n",
      "Epoch: 036, Train Loss: -0.66028583, Val NMI: 0.0002, Test NMI: 0.0002\n",
      "Epoch: 037, Train Loss: -0.66595489, Val NMI: 0.0002, Test NMI: 0.0002\n",
      "Epoch: 038, Train Loss: -0.67105830, Val NMI: 0.0002, Test NMI: 0.0002\n",
      "Epoch: 039, Train Loss: -0.67567915, Val NMI: 0.0003, Test NMI: 0.0003\n",
      "Epoch: 040, Train Loss: -0.67991835, Val NMI: 0.0002, Test NMI: 0.0002\n",
      "Epoch: 041, Train Loss: -0.68384212, Val NMI: 0.0001, Test NMI: 0.0001\n",
      "Epoch: 042, Train Loss: -0.68747467, Val NMI: 0.0001, Test NMI: 0.0001\n",
      "Epoch: 043, Train Loss: -0.69085878, Val NMI: 0.0001, Test NMI: 0.0001\n",
      "Epoch: 044, Train Loss: -0.69399059, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 045, Train Loss: -0.69690925, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 046, Train Loss: -0.69962645, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 047, Train Loss: -0.70217294, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 048, Train Loss: -0.70457321, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 049, Train Loss: -0.70683044, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 050, Train Loss: -0.70895475, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 051, Train Loss: -0.71096647, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 052, Train Loss: -0.71290618, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 053, Train Loss: -0.71481156, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 054, Train Loss: -0.71668053, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 055, Train Loss: -0.71847516, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 056, Train Loss: -0.72014594, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 057, Train Loss: -0.72165734, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 058, Train Loss: -0.72301537, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 059, Train Loss: -0.72426647, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 060, Train Loss: -0.72543675, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 061, Train Loss: -0.72651631, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 062, Train Loss: -0.72743469, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 063, Train Loss: -0.72816300, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 064, Train Loss: -0.72900879, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 065, Train Loss: -0.73049510, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 066, Train Loss: -0.73140579, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 067, Train Loss: -0.73194253, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 068, Train Loss: -0.73317754, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 069, Train Loss: -0.73421586, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 070, Train Loss: -0.73478740, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 071, Train Loss: -0.73569030, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 072, Train Loss: -0.73662108, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 073, Train Loss: -0.73718953, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 074, Train Loss: -0.73777962, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 075, Train Loss: -0.73853695, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 076, Train Loss: -0.73917270, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 077, Train Loss: -0.73965734, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 078, Train Loss: -0.74025631, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 079, Train Loss: -0.74093825, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 080, Train Loss: -0.74145174, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 081, Train Loss: -0.74191672, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 082, Train Loss: -0.74250436, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 083, Train Loss: -0.74304461, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 084, Train Loss: -0.74344790, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 085, Train Loss: -0.74384004, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 086, Train Loss: -0.74428463, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 087, Train Loss: -0.74471521, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 088, Train Loss: -0.74506986, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 089, Train Loss: -0.74540806, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 090, Train Loss: -0.74579877, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 091, Train Loss: -0.74619800, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 092, Train Loss: -0.74655503, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 093, Train Loss: -0.74686968, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 094, Train Loss: -0.74716735, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 095, Train Loss: -0.74746740, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 096, Train Loss: -0.74774802, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 097, Train Loss: -0.74799854, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 098, Train Loss: -0.74821764, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 099, Train Loss: -0.74841636, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 100, Train Loss: -0.74860895, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 101, Train Loss: -0.74880123, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 102, Train Loss: -0.74900150, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 103, Train Loss: -0.74920249, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 104, Train Loss: -0.74940830, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 105, Train Loss: -0.74961114, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 106, Train Loss: -0.74981576, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 107, Train Loss: -0.75002152, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 108, Train Loss: -0.75023371, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 109, Train Loss: -0.75045449, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 110, Train Loss: -0.75067604, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 111, Train Loss: -0.75085163, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 112, Train Loss: -0.75096601, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 113, Train Loss: -0.75098491, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 114, Train Loss: -0.75096130, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 115, Train Loss: -0.75076210, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 116, Train Loss: -0.75095558, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 117, Train Loss: -0.75119162, Val NMI: 0.0000, Test NMI: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 118, Train Loss: -0.75166291, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 119, Train Loss: -0.75181323, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 120, Train Loss: -0.75168252, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 121, Train Loss: -0.75166380, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 122, Train Loss: -0.75178993, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 123, Train Loss: -0.75214320, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 124, Train Loss: -0.75228494, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 125, Train Loss: -0.75221425, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 126, Train Loss: -0.75221086, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 127, Train Loss: -0.75232643, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 128, Train Loss: -0.75257736, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 129, Train Loss: -0.75269455, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 130, Train Loss: -0.75267452, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 131, Train Loss: -0.75268054, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 132, Train Loss: -0.75275958, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 133, Train Loss: -0.75294423, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 134, Train Loss: -0.75307083, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 135, Train Loss: -0.75310951, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 136, Train Loss: -0.75312012, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 137, Train Loss: -0.75315374, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 138, Train Loss: -0.75327384, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 139, Train Loss: -0.75340450, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 140, Train Loss: -0.75351954, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 141, Train Loss: -0.75359792, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 142, Train Loss: -0.75365424, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 143, Train Loss: -0.75371879, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 144, Train Loss: -0.75379258, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 145, Train Loss: -0.75389862, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 146, Train Loss: -0.75399309, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 147, Train Loss: -0.75407881, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 148, Train Loss: -0.75414854, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 149, Train Loss: -0.75422210, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Epoch: 150, Train Loss: -0.75429881, Val NMI: 0.0000, Test NMI: 0.0000\n",
      "Best Val NMI: 0.0004, Test NMI: 0.0004\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = best_test_acc = 0\n",
    "for epoch in range(1, 151):\n",
    "    train_loss = train(epoch)\n",
    "    val_acc = test()\n",
    "    test_acc = test()\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_test_acc = test_acc\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.8f}, '\n",
    "          f'Val NMI: {val_acc:.4f}, Test NMI: {test_acc:.4f}')\n",
    "print(f'Best Val NMI: {best_val_acc:.4f}, Test NMI: {best_test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469d5f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45764dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da49185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
